{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recitation 2: Regression & Time Series\n",
    "The following function will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Mean Absolute Percentage Error (MAPE) for training and testing data\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return (100 * abs((y_true - y_pred) / y_true)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_error(actual, forecast):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Percentage Error (MAPE)\n",
    "    \n",
    "    Parameters:\n",
    "    - actual: list of actual values\n",
    "    - forecast: list of forecasted values\n",
    "    \n",
    "    Returns:\n",
    "    - MAPE: Mean Absolute Percentage Error\n",
    "    \"\"\"\n",
    "    n = len(actual)\n",
    "    if n == 0 or len(forecast) != n:\n",
    "        raise ValueError(\"Input lists must be of same non-zero length\")\n",
    "    \n",
    "    mape = sum(abs((a - f) / a) for a, f in zip(actual, forecast)) / n * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, check that every package that we will use is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# If a package is missing, install it by writing !pip install package_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"boston_housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Boston Housing dataset, the target variable is:\n",
    "\n",
    "- MEDV: Median value of owner-occupied homes in $1000s.\n",
    "\n",
    "This is the variable that we typically try to predict based on the other features in the dataset when performing regression analyses. Essentially, it represents the median price of homes in various areas of Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 'RM' feature (average number of rooms per dwelling) to predict 'MEDV' (Median value of owner-occupied homes)\n",
    "X = df['RM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant (for intercept)\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some indices from the dataset for the analysis\n",
    "X_sample = X.iloc[0:400]\n",
    "y_sample = y[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the regression model\n",
    "model = sm.OLS(y_sample, X_sample).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting model results\n",
    "slope_estimate = model.params['RM']\n",
    "p_value = model.pvalues['RM']\n",
    "r_squared = model.rsquared\n",
    "\n",
    "# Plotting Fitted Values vs. Residuals\n",
    "fitted_values = model.fittedvalues\n",
    "residuals = model.resid\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(fitted_values, residuals, alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values - Example')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Fitted Values vs. Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "slope_estimate, p_value, r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X-axis (Fitted Values): These are the predicted values of the dependent variable (in this case, the median home value, MEDV) based on the regression model.\n",
    "\n",
    "- Y-axis (Residuals): The residuals represent the difference between the observed values (actual data) and the fitted values (predictions). Specifically:\n",
    "\n",
    "Residual= Observed Value− Fitted Value\n",
    "\n",
    "- Horizontal Line at Residuals = 0: This line signifies where the prediction matches the actual value perfectly. Residuals above the line indicate under-prediction by the model, while residuals below the line indicate over-prediction.\n",
    "\n",
    "The purpose of the Fitted Values vs. Residuals plot is to check the assumptions of the linear regression model, particularly:\n",
    "\n",
    "1. Linearity: The relationship between the predictors and the response should be linear.\n",
    "2. Independence: The residuals are independent.\n",
    "3. Homoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\n",
    "4. Normality: The residuals should be approximately normally distributed.\n",
    "For a well-fitting model:\n",
    "\n",
    "The residuals should be randomly scattered around the horizontal line at 0.\n",
    "There shouldn't be any clear pattern or trend in the residuals.\n",
    "If we see patterns in this plot, it may indicate potential problems with the model, such as non-linearity, non-constant variance (heteroscedasticity), or outliers.\n",
    "\n",
    "**In this plot** the residuals seem to be reasonably scattered around the horizontal line at 0. This suggests that the model's errors are random, which is a good sign.\n",
    "There's no clear funnel shape, which would indicate heteroscedasticity (non-constant variance of errors). This is also positive.\n",
    "There doesn't appear to be any distinct curve or pattern in the residuals, suggesting the linearity assumption might hold.\n",
    "However, there are a few considerations:\n",
    "\n",
    "Some points are far from the central cluster, hinting at potential outliers or high-leverage points.\n",
    "A more thorough analysis would involve other diagnostic plots and tests, such as a quantile-quantile (Q-Q) plot to check the normality of residuals or leverage vs. residual plots to identify influential points.\n",
    "Overall, based solely on the Fitted Values vs. Residuals plot, the model seems reasonably good. The residuals appear random and without any clear patterns. However, a comprehensive evaluation of a regression model would involve examining multiple diagnostic plots and statistics to ensure all assumptions are met and that the model is robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. R-squared and Adjusted R-squared: **R-squared: 0.567**. This indicates that approximately 56.7% of the variability in the median home values can be explained by the average number of rooms per dwelling in this subset of the data. Adjusted R-squared: 0.566. It's very close to the R-squared value, indicating that most of the included predictors (in this case, just 'RM') are relevant to the model.\n",
    "2. F-statistic and its associated p-value: The F-statistic tests the hypothesis that all regression coefficients are equal to zero (meaning the model fits no better than a horizontal line or a model with no predictors). A significant F-statistic (in this case, very close to zero) indicates that the predictors are valuable.\n",
    "3. Coefficients and their Significance: Intercept (const): -35.2609. This is the predicted median home value when RM is zero (though it doesn't have a practical interpretation since a dwelling can't have zero rooms). **RM: 9.4055**. This indicates that for every additional room, the median value of homes increases by about \\$9,406, holding other factors constant. Both coefficients have p-values very close to zero, indicating that they are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression results on the data\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Scatter plot of the data\n",
    "plt.scatter(X_sample['RM'], y_sample, label='Data', alpha=0.6)\n",
    "\n",
    "# Regression line\n",
    "plt.plot(X_sample['RM'], fitted_values, color='red', label='Regression Line')\n",
    "\n",
    "plt.title('Regression of Median Home Value on Number of Rooms')\n",
    "plt.xlabel('Average Number of Rooms per Dwelling (RM)')\n",
    "plt.ylabel('Median Value of Owner-occupied Homes (in $1000s)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the model\n",
    "predicted_values_multivariate = model.predict(X_sample)\n",
    "\n",
    "# Calculating the error metrics\n",
    "MAE = mean_absolute_error(y_sample, predicted_values_multivariate)\n",
    "RMSE = mean_squared_error(y_sample, predicted_values_multivariate, squared=False)\n",
    "MAPE = np.mean(np.abs((y_sample - predicted_values_multivariate) / y_sample)) * 100\n",
    "R_squared = model.rsquared\n",
    "print(\"MAE\", MAE, \"\\nRMSE\", RMSE, \"\\nMAPE\", MAPE,\"\\nR2\", R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE, RMSE, and MAPE provide insights into the model's prediction accuracy. Low values of MAE and RMSE, along with the high R-squared suggest that a model provides a good fit to the data and makes reasonably accurate predictions. \n",
    "\n",
    "However, always consider the context and the domain when interpreting these metrics. For instance, in a scenario where housing prices range widely, an MAE of $1867.60 might be considered very good. However, in a market with more consistent and narrow-ranging prices, the same error might be seen as less acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "We do the same but with $X = ['RM', 'LSTAT', 'PTRATIO']$ as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple features to predict 'MEDV' (Median value of owner-occupied homes)\n",
    "# We'll use 'RM' (average number of rooms), 'LSTAT' (% lower status of the population), and 'PTRATIO' (pupil-teacher ratio by town) for this example\n",
    "features = ['RM', 'LSTAT', 'PTRATIO']\n",
    "X_multivariate = df[features]\n",
    "\n",
    "# Adding a constant (for intercept)\n",
    "X_multivariate = sm.add_constant(X_multivariate)\n",
    "\n",
    "# Selecting the same indices from our previous sample for consistency\n",
    "X_multivariate_sample = X_multivariate.iloc[1:400]\n",
    "y_multivariate_sample = y[1:400]\n",
    "\n",
    "# Fitting the multivariate regression model using the first 400 data points\n",
    "model_multivariate = sm.OLS(y_multivariate_sample, X_multivariate_sample).fit()\n",
    "\n",
    "# 1. Fitted Values vs. Residuals\n",
    "fitted_values_multivariate = model_multivariate.fittedvalues\n",
    "residuals_multivariate = model_multivariate.resid\n",
    "\n",
    "# 2. Q-Q Plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "# Plotting Fitted Values vs. Residuals\n",
    "axes.scatter(fitted_values_multivariate, residuals_multivariate, alpha=0.6)\n",
    "axes.axhline(0, color='red', linestyle='--')\n",
    "axes.set_title('Fitted Values vs. Residuals')\n",
    "axes.set_xlabel('Fitted Values')\n",
    "axes.set_ylabel('Residuals')\n",
    "axes.grid(True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted values\n",
    "predicted_values = model_multivariate.fittedvalues\n",
    "\n",
    "# Plotting with appropriate labels\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(y_multivariate_sample, predicted_values, alpha=0.6, label='Data Points')\n",
    "plt.plot([min(y_multivariate_sample), max(y_multivariate_sample)], \n",
    "         [min(y_multivariate_sample), max(y_multivariate_sample)], \n",
    "         color='red', linestyle='--', label='Perfect Prediction Line')\n",
    "plt.xlabel('Actual Median Home Values ($1000s)')\n",
    "plt.ylabel('Predicted Median Home Values ($1000s)')\n",
    "plt.title('Actual vs. Predicted Home Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multivariate.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **R-squared and Adjusted R-squared**:\n",
    "- **R-squared**: 0.671. This metric denotes that approximately 67.1% of the variability in the median home values can be accounted for by our model using the three predictor variables.\n",
    "- **Adjusted R-squared**: 0.668. A slight decrease from the R-squared value, which is expected as it adjusts for the number of predictors in the model. This close value indicates the predictors are relevant.\n",
    "\n",
    "##### **F-statistic and its associated p-value**:\n",
    "- The **F-statistic** tests the overall significance of the model. With a p-value close to zero, this demonstrates that at least one of the predictors is significant.\n",
    "\n",
    "##### **Coefficients and their Significance**:\n",
    "- **Intercept (const)**: 5.5940. This is the median home value when all predictors are zero. However, this doesn't necessarily have a direct practical meaning.\n",
    "- **RM**: 5.7950. For every additional room, the median value of homes is predicted to increase by about \\$5,795, holding other variables constant.\n",
    "- **LSTAT**: -0.4784. For every 1\\% increase in the lower status of the population, the median value of homes is predicted to decrease by about \\$478.\n",
    "- **PTRATIO**: -0.6986. For every unit increase in the pupil-teacher ratio, the median value of homes is predicted to decrease by about $698.\n",
    "- All predictors have p-values very close to zero, signifying their statistical significance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting values using the model\n",
    "predicted_values_multivariate = model_multivariate.predict(X_multivariate_sample)\n",
    "\n",
    "# Calculating the error metrics\n",
    "MAE = mean_absolute_error(y_multivariate_sample, predicted_values_multivariate)\n",
    "RMSE = mean_squared_error(y_multivariate_sample, predicted_values_multivariate, squared=False)\n",
    "MAPE = calculate_mape(y_multivariate_sample, predicted_values_multivariate)\n",
    "R_squared = model_multivariate.rsquared\n",
    "MAE, RMSE, MAPE, R_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE, RMSE, and MAPE provide insights into the model's prediction accuracy. The relatively low values of MAE and RMSE, along with the high R-squared, suggest that the model provides a good fit to the data and makes reasonably accurate predictions. However, always consider the context and the domain when interpreting these metrics. For instance, in a scenario where housing prices range widely, an MAE of $1867.60 might be considered very good. However, in a market with more consistent and narrow-ranging prices, the same error might be seen as less acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in some data on Monthly Average Temperature in Alaska.\n",
    "\n",
    "\n",
    "Source: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(\"Alaska_AvgTemp.csv\")\n",
    "print(df.head())\n",
    "print(df['Date'].dtype)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we are working with dates, it is better to transform them in the 'datetime' format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot style and size\n",
    "plt.figure(figsize=(5, 7))\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(df['Date'], df['AverageTemperature'], color='dodgerblue', linewidth=2, label='Average Temperature')\n",
    "plt.fill_between(df['Date'], df['AverageTemperature'], color='dodgerblue', alpha=0.1)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Monthly Average Temperature in Alaska (1950 onwards)', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Temperature (°C)', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform the 'data' Dataframe into a Series with monthly frequency ('MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AverageTemperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data with monthly frequency\n",
    "temp = pd.Series(df['AverageTemperature'].values, index=df['Date'])\n",
    "temp.index.freq = 'MS'  # Monthly start frequency\n",
    "\n",
    "# Decomposing the time series\n",
    "decomp = seasonal_decompose(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the figure and axes\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "# Observed\n",
    "axes[0].plot(decomp.observed, color='dodgerblue')\n",
    "axes[0].set_title('Observed')\n",
    "axes[0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(decomp.trend, color='dodgerblue')\n",
    "axes[1].set_title('Trend')\n",
    "axes[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(decomp.seasonal, color='dodgerblue')\n",
    "axes[2].set_title('Seasonal')\n",
    "axes[2].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Residual as a line plot\n",
    "axes[3].plot(decomp.resid, color='dodgerblue')\n",
    "axes[3].set_title('Residual')\n",
    "axes[3].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Adjusting the layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time series data, we usually split our training and test sets by date (before/after a certain time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "train = df[df['Date'] <= \"2000-01-01\"]\n",
    "test = df[df['Date'] > \"2000-01-01\"]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ARIMA()` function from the `statsmodels.tsa.arima.model` package let's use fit an ARIMA model with order = (p, d, q). Let's create a time series object of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA model\n",
    "temp_train = pd.Series(train['AverageTemperature'].values, index=train['Date'])\n",
    "\n",
    "# 'MS' stands for \"Month Start frequency\". It indicates that each data point represents the start of a month.\n",
    "temp_train.index.freq = 'MS'\n",
    "\n",
    "mod1 = ARIMA(temp_train, order=(2, 1, 1))\n",
    "results1 = mod1.fit()\n",
    "print(results1.summary())\n",
    "\n",
    "# Accuracy\n",
    "print(results1.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "forecast1 = results1.forecast(steps=4)\n",
    "print(forecast1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `auto_arima()` function does automatic model selection for us, and computes the \"best-fit\" (p, d, q)(P, D, Q).\n",
    "\n",
    "Examples in the choice of $m$:\n",
    "- Daily data with weekly patterns: $m=7$.\n",
    "- Monthly data with yearly patterns: $m=12$.\n",
    "- Hourly data with daily patterns: $m=24$ (assuming patterns repeat every day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Auto ARIMA\n",
    "mod2 = auto_arima(temp_train, seasonal=True, m=12, trace=True, error_action='ignore', suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameters\n",
    "p, d, q = mod2.order\n",
    "P, D, Q, s = mod2.seasonal_order\n",
    "\n",
    "print(f\"The ARIMA parameters are p = {p}, d = {d}, q = {q}\")\n",
    "print(f\"The seasonal ARIMA parameters are P = {P}, D = {D}, Q = {Q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitted values and residuals\n",
    "fitted = mod2.predict_in_sample()\n",
    "residuals = temp_train - fitted\n",
    "\n",
    "# Predictions\n",
    "forecast2 = mod2.predict(n_periods=163)\n",
    "train_pred = fitted\n",
    "test_pred = forecast2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAPE\n",
    "train_mape = calculate_mape(train['AverageTemperature'].values, train_pred)\n",
    "test_mape = calculate_mape(test['AverageTemperature'].values, test_pred)\n",
    "print(\"Training MAPE:\", train_mape)\n",
    "print(\"Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
