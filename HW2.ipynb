{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.774/15.780 Fall 2023\n",
    "## The Analytics of Operations Management\n",
    "### Problem Set 2 - Logistic Regression & Data Cleaning\n",
    "#### Due Date:  10/06\n",
    "---\n",
    "Name of Student: [Joy Bhattacharya]\n",
    "\n",
    "MIT ID Number: [922631264]\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1) Submit solutions that are your own, in your own words. You are allowed to discuss with other students in general terms, but make sure you are not copying verbatim from another student. Therefore do not read other students' solutions. If you use material from outside this class, reference it in your solution. \n",
    "\n",
    "2) Please download the python file attached in the assignment and complete your answers there in the same file. Read the questions carefully, and make sure you answer every part that the question asks.\n",
    "\n",
    "3) Include relevant code in the PDF submission even if the question doesn't explicitly ask for it. Upload your solutions as a PDF file. Include your name and MIT ID on the first page.\n",
    "\n",
    "4) To convert to pdf, you can use the \"print to pdf\" option in jupyter (or equivalent options in other IDE). There are other options to directly download in to pdf format which might include additional installation of packages. \n",
    "\n",
    "5) Show your work and explain your conclusions clearly and precisely. Plots should have clear titles and axis labels so that it is clear what your analysis is showing.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the packages we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages you do not have\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joyse\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "np.float=float\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $\\textbf{Problem 1.}$ (Logistic Regression) (40 pts)\n",
    "\n",
    "Historically, lending money to individuals has been done by banks, credit unions, and savings and loan associations. There has been a recent uptick in what is known as peer-to-peer lending, where one individual loans money to another (2015 market share of $\\$26.2$ billion). We have data from LendingClub.com, the world’s largest peer-to-peer lending platform, which issued $\\$13.4$ billion in loans from its founding in 2006 through October 2015. \n",
    "\n",
    "Our data is a subset of these loans: \n",
    "  * 9,516 3-year loans funded by them between May 2007 and February 2010.\n",
    "  * We have information on whether the loan was not paid in full (**1 if not paid in full, zero otherwise**).\n",
    "  * We also have 6 covariates available at the time the loan was granted, including Monthly loan installment, log annual income, FICO score, revolving balance on credit cards, number of credit inquiries over the past six months, and number of deleterious public records.\n",
    "  * These represent just a tiny portion of the covariates LendingClub.com would actually have access to when making a loan decision. Using this data, stored in the data set loans.csv,\n",
    "\n",
    "We will try to **build a model for correctly predicting the probability that an individual defaults on the loan**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_fully_paid</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>fico</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>is_training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>829.10</td>\n",
       "      <td>4.929419</td>\n",
       "      <td>737</td>\n",
       "      <td>28.854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>228.22</td>\n",
       "      <td>4.812913</td>\n",
       "      <td>707</td>\n",
       "      <td>33.623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>366.86</td>\n",
       "      <td>4.505150</td>\n",
       "      <td>682</td>\n",
       "      <td>3.511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>162.34</td>\n",
       "      <td>4.929419</td>\n",
       "      <td>712</td>\n",
       "      <td>33.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>102.92</td>\n",
       "      <td>4.907411</td>\n",
       "      <td>667</td>\n",
       "      <td>4.740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_fully_paid  installment  log_annual_inc  fico  revol_bal  \\\n",
       "0               0       829.10        4.929419   737     28.854   \n",
       "1               0       228.22        4.812913   707     33.623   \n",
       "2               0       366.86        4.505150   682      3.511   \n",
       "3               0       162.34        4.929419   712     33.667   \n",
       "4               0       102.92        4.907411   667      4.740   \n",
       "\n",
       "   inq_last_6mths  pub_rec  is_training_data  \n",
       "0               0        0              True  \n",
       "1               0        0             False  \n",
       "2               1        0             False  \n",
       "3               1        0              True  \n",
       "4               0        0              True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'loans.csv' is in the same directory as your Python script or Jupyter Notebook\n",
    "file_path = \"loans.csv\"\n",
    "\n",
    "# Use the read_csv function to load the CSV file into a DataFrame\n",
    "loans = pd.read_csv(file_path)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (6661, 7)\n",
      "Test set shape: (2855, 7)\n"
     ]
    }
   ],
   "source": [
    "# Use the column 'is_training_data' to split the set into training and test data (True is training and False is test)\n",
    "loans_train = loans[loans['is_training_data'] == True]\n",
    "loans_test = loans[loans['is_training_data'] == False]\n",
    "\n",
    "# Delete the column 'is_training_data' as we do not want it to be part of the model (is not an actual feature of loans)\n",
    "del loans_train['is_training_data']\n",
    "del loans_test['is_training_data']\n",
    "\n",
    "print(\"Train set shape:\", loans_train.shape)\n",
    "print(\"Test set shape:\", loans_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. Run a simple logistic regression of `not_fully_paid` on `fico`, on your training data. Write down an equation that gives the estimated conditional probability of defaulting, given a FICO score x, and use it to predict the probability of defaulting for individuals with a FICO score of 700 and 650, respectively. Do this two ways: one by directly plugging in values to your equation, and another by using the `predict` function of your model. Report and comment your results. **(10 pts)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We first train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.425939\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         not_fully_paid   No. Observations:                 6661\n",
      "Model:                          Logit   Df Residuals:                     6659\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 02 Oct 2023   Pseudo R-squ.:                 0.03081\n",
      "Time:                        14:06:12   Log-Likelihood:                -2837.2\n",
      "converged:                       True   LL-Null:                       -2927.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.948e-41\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          7.3642      0.702     10.496      0.000       5.989       8.739\n",
      "fico          -0.0128      0.001    -12.773      0.000      -0.015      -0.011\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the dependent variable (y) and predictor variable (X)\n",
    "y_train_11 = loans_train[\"not_fully_paid\"]\n",
    "X_train_11 = loans_train[\"fico\"]\n",
    "\n",
    "# Add a constant term to the predictor variable (intercept)\n",
    "X_train_11 = sm.add_constant(X_train_11)\n",
    "\n",
    "# Fit the linear regression model\n",
    "log_reg_11 = sm.Logit(y_train_11, X_train_11).fit()\n",
    "\n",
    "# Get the model summary\n",
    "summary = log_reg_11.summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Probability of default (first approach: manual equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16848836377007184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 'fico' and 'intercept' coefficients\n",
    "fico_coeff = log_reg_11.params[\"fico\"]\n",
    "intercept_coeff = log_reg_11.params[\"const\"]\n",
    "\n",
    "# Define your equation as a lambda function so that we can reuse it\n",
    "default_prob_equation = lambda x: np.exp(intercept_coeff + fico_coeff * x) / (1 + np.exp(intercept_coeff + fico_coeff * x))\n",
    "\n",
    "\n",
    "# Evaluate the expression for a FICO score of 700 and report the value\n",
    "p_700 = default_prob_equation(700)\n",
    "p_700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2776120401174487"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the expression for a FICO score of 650 and report the value\n",
    "p_650 = default_prob_equation(650)\n",
    "p_650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Probability of default (second approach: model's prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.168488\n",
       "1    0.277612\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the test set with the 2 values 700 and 650  (Hint: Define it as a pandas DataFrame)\n",
    "X_test_11 = pd.DataFrame({\"fico\": [700,650]})\n",
    "\n",
    "# Add a constant term to the predictor variable (intercept)\n",
    "X_test_11 = sm.add_constant(X_test_11)\n",
    "\n",
    "# Predict the probabilities of default and report those values\n",
    "probs_11 = log_reg_11.predict(X_test_11)\n",
    "probs_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:** Both methods predict the same thing. The p-value of the fico score is less than 0.05, which means it is statistically significant and should be included in the model because it's a good predictor. The coefficient on the fico score is -0.0128, indicating that there is a negative relationship between fico credit score and the probability of defaulting (the higher your credit score, the lower your probability of defaulting). With our logistic model, a person with a fico score of 700, holding all else constant, is predicted to have a 0.1684 probability of defaulting. A person with a 650 fico score has an expected probability of 0.277 of defaulting holding all else constant. This makes sense because we would expect someone with a lower credit score to be more likely to default since credit scores are lower the less trustworthy you are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2**. Construct a multiple logistic regression model that predicts `not_fully_paid` as a function of all of the covariates in the data set. Based on this multiple regression model, is there evidence that including `fico` in the model improved performance over a model including every variable except for `fico`? **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413768\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         not_fully_paid   No. Observations:                 6661\n",
      "Model:                          Logit   Df Residuals:                     6654\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Mon, 02 Oct 2023   Pseudo R-squ.:                 0.05851\n",
      "Time:                        14:06:25   Log-Likelihood:                -2756.1\n",
      "converged:                       True   LL-Null:                       -2927.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.145e-71\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             10.0152      0.992     10.098      0.000       8.071      11.959\n",
      "installment        0.0011      0.000      6.070      0.000       0.001       0.002\n",
      "log_annual_inc    -0.9673      0.159     -6.099      0.000      -1.278      -0.656\n",
      "fico              -0.0111      0.001    -10.564      0.000      -0.013      -0.009\n",
      "revol_bal          0.0052      0.001      4.718      0.000       0.003       0.007\n",
      "inq_last_6mths     0.1372      0.014      9.622      0.000       0.109       0.165\n",
      "pub_rec            0.2188      0.118      1.860      0.063      -0.012       0.449\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the features of the model\n",
    "features_12 = [\"installment\", \"log_annual_inc\", \"fico\", \"revol_bal\", \"inq_last_6mths\", \"pub_rec\"]\n",
    "\n",
    "# Define the dependent variable (y) and predictor variable (X)\n",
    "y_train_12 = loans_train[\"not_fully_paid\"]\n",
    "X_train_12 = loans_train[features_12]\n",
    "\n",
    "# Add a constant term to the predictor variable (intercept)\n",
    "X_train_12 = sm.add_constant(X_train_12)\n",
    "\n",
    "# Fit the linear regression model\n",
    "log_reg_12 = sm.Logit(y_train_12, X_train_12).fit()\n",
    "\n",
    "# Get the model summary\n",
    "summary = log_reg_12.summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const             5.615125e-24\n",
       "installment       1.276738e-09\n",
       "log_annual_inc    1.069739e-09\n",
       "fico              4.392585e-26\n",
       "revol_bal         2.385457e-06\n",
       "inq_last_6mths    6.447360e-22\n",
       "pub_rec           6.291805e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zoom-in on the actual p-values\n",
    "log_reg_12.pvalues\n",
    "# FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Based on this multiple regression model, there is evidence that including fico in the model improved our performance over a model including every variable except for fico. This is because when we include fico in the multi-feature model, the p-value of fico is extremely small, much less than 0.05. This means that it is statistically significant and should be included in the model and therefore improves the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "**3.** A highly simplified analysis leads LendingClub.com to the following conclusion: If an individual defaults on their loan and can’t pay it back, we incur a profit of $-\\$4000$ (i.e. a loss of $\\$4000$). If the individual does not default, we realize a profit of $\\$1000$. \n",
    "\n",
    "Based on this, for what estimated values of probability for default should I not give the individual a loan in the first place (hence guaranteeing an expected profit of $0)? Note: You do not have to write code for this question. Explain your computations in the answer cell **(10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Let p_d be the probaility of default. LendingClub.com's expected profit is as follows and they only want to lend when their expected profit is above 0: p_d(-4000)+(1-p_d)(1000)>0. This equation is satisfied for p_d<1/5. So, we would NOT want to give the individual a loan in the first place if p_d>1/5. So, if they have a probability of default greater than 0.2 we wouldn't want to give them a loan because then our expected profit would be negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "**4.** For the multiple logistic regression model, use this break-even probability as a threshold to classify whether or not an individual would default (that is, you will predict “Default” if someone is predicted above your probability in part **1.3** and “No Default” otherwise). Based on this rule, report the confusion matrix of your predicted outcome and the actual outcome with respect to the **test set**. After doing so,\n",
    "provide the following summary measures of performance: \n",
    "* Accuracy\n",
    "* Sensitivity (True Positive Rate)\n",
    "* Specificity (True Negative Rate)\n",
    "**(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the dependent variable (y) and predictor variable (X) (Hint: same features as in 1.2)\n",
    "y_test_14 = loans_test[\"not_fully_paid\"]\n",
    "X_test_14 = loans_test[features_12]\n",
    "\n",
    "# Add a constant term to the predictor variable (intercept)\n",
    "X_test_14 = sm.add_constant(X_test_14)\n",
    "\n",
    "# Predict default probabilities with the model \n",
    "default_probs_14 = log_reg_12.predict(X_test_14)\n",
    "\n",
    "# Use the probability of 1.3 to transform the probabilities into 0-1 predictions\n",
    "default_preds_14 = (default_probs_14 > 0.2)\n",
    "\n",
    "# Compute and show the confusion matrix\n",
    "cm_14 = confusion_matrix(y_test_14, default_preds_14)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_14)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716\n",
      "Sensitivity (True Positive Rate): 0.390\n",
      "Specificity (True Negative Rate): 0.777\n"
     ]
    }
   ],
   "source": [
    "# Compute and report all the metrics \n",
    "TN, FP = 1865, 534\n",
    "FN, TP = 278, 178\n",
    "\n",
    "ACC = (TN + TP) / (TN + FN + TP +FP) \n",
    "print(f\"Accuracy: {ACC:.3f}\")\n",
    "\n",
    "TPR = TP / (TP + FN)  \n",
    "print(f\"Sensitivity (True Positive Rate): {TPR:.3f}\")\n",
    "\n",
    "TNR = TN / (TN + FP) \n",
    "print(f\"Specificity (True Negative Rate): {TNR:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## $\\textbf{Problem 2.}$ (Data Cleaning) (40 pts)\n",
    "\n",
    "In this problem, we will explore Outliers Removal and Missing Data Imputation techniques. The problem is based on the Boston Housing dataset. A brief description of the dataset is the following:\n",
    "\n",
    "*This dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.*\n",
    "\n",
    "For additional information, please visit this [Link](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html#:~:text=The%20Boston%20Housing%20Dataset,the%20area%20of%20Boston%20Mass.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'housing.csv' is in the same directory as your Python script or Jupyter Notebook\n",
    "file_path = \"housing.csv\"\n",
    "\n",
    "# Use the read_csv function to load the CSV file into a DataFrame\n",
    "housing = pd.read_csv(file_path)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. There are two rows that contain outlier values for the variable `age`. Use a box plot to detect them and report their values. Explain why those values are incorrect and eliminate those rows from the dataset. Briefly comment on what could be the source of error and suggest a quick fix (*Note: You do not have to implement the fix, you already removed those rows*) **(10 pts)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20de155c5e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a box plot to detect the outliers\n",
    "housing.age.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20de15c6610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove those points\n",
    "housing = housing[housing[\"age\"] <= 100]\n",
    "\n",
    "# Use a box plot again after removing the outliers to check the removal\n",
    "\n",
    "housing.age.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The outlier values from the boxplot are at around 480 and 980. Those values are incorrect because age is a proportion, meaning it should be under 100 after it is converted to percent form (which presumably it is in this dataset). So we know that any age value above 100 is incorrect. I'm assuming that the reason those are incorrect is some form of human error. Maybe those values were typed in correctly (an extra 0 was added, numbers were flipped, etc). One way to quickly fix this is to see if there is a pattern in the errors (maybe a 0 was added to the end and we can just delete that). If we could find a pattern, we could try to correct those data values. If not, we should just delete them as we do later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Checkpoint** To make sure you have removed the rows, run the following code before continuing the next sections. If you get errors, you have not removed them correctly. It should run without printing any error. (This part is not graduated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(housing) == 504\n",
    "assert housing.age.mean().round() == 69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**2.** Find all the variables that contain any missing values. For each of them report the percentage of missing values. **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim    0.037698\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the percentage of missing values for each variable\n",
    "nan_perc = housing.isna().mean()\n",
    "\n",
    "# Filter those that contain nans\n",
    "nan_perc = nan_perc[nan_perc > 0]\n",
    "\n",
    "nan_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** 3.7698% of the crim values are missing in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**3.** Impute `crim` values using the **mean** and the **median**. For that follow these steps:\n",
    "* Randomly split the data into training ($80\\%$ of rows.) and test ($20\\%$ of rows). Code is provided for this step, please do not change the seed or the split percentage.\n",
    "* Compute the **mean** and **median** `crim` values in the training. We will use this value for the test set.\n",
    "* Report the MAPE of these imputations in the test set. Which model is more accurate? **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE function\n",
    "def compute_mape(y_true, y_pred):\n",
    "    return (100 * abs((y_true - y_pred) / y_true)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3429.341631880411"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep first only the data that has values for crim\n",
    "housing_no_nas = housing[~housing.crim.isna()]\n",
    "\n",
    "# Split your data in 80% train and 20% test (do not modify the seed or the split percentage)\n",
    "np.random.seed(15774)\n",
    "housing_no_nas_train, housing_no_nas_test = train_test_split(housing_no_nas, train_size=0.8)\n",
    "\n",
    "# Build X and y for test and train\n",
    "features_22 = ['crim']\n",
    "X_train_22 = housing_no_nas_train[features_22]\n",
    "y_train_22 = housing_no_nas_train['crim']\n",
    "X_test_22 = housing_no_nas_test[features_22]\n",
    "y_test_22 = housing_no_nas_test['crim']\n",
    "\n",
    "# Compute the mean crim in the train set\n",
    "mean_crim_train = X_train_22.crim.mean()\n",
    "\n",
    "# Compute and report the MAPE\n",
    "compute_mape(y_test_22, mean_crim_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.7671207960982"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the median crim in the train set\n",
    "median_crim_train = X_train_22.crim.median()\n",
    "\n",
    "# Compute and report the MAPE\n",
    "compute_mape(y_test_22, median_crim_train, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: The MAPE of the mean model is 3429.34. The MAPE of the median model is 208.767. This means that the median model is more accurate because it has a much lower MAPE, meaning that our predictions on average are 208% percent off from the actual values (whereas our predictions are 3429% off in the mean model). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**4.** Impute `crim` values using a **knn** model with 3 and 5 neighbors. For that follow these steps:\n",
    "* We will use the random train-test split we computed in 2.3. No need to copy it again, simply use the same sets `housing_no_nas_train` and `housing_no_nas_test`.\n",
    "* The set of predictors is all the variables except from `crim`\n",
    "* Train a `KNeighborsRegressor` with 3 neighbors with the training data\n",
    "* Report the MAPE of these imputations in the test set\n",
    "* Repeat last two steps with a `KNeighborsRegressor` with 5 neighbors\n",
    "* Which model is better? Are they better than the previous models?  **(15 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.33771503216866"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build X and y for test and train\n",
    "features_23 = [\"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\"]\n",
    "X_train_23 = housing_no_nas_train[features_23]\n",
    "y_train_23 = housing_no_nas_train['crim']\n",
    "X_test_23 = housing_no_nas_test[features_23]\n",
    "y_test_23 = housing_no_nas_test['crim']\n",
    "\n",
    "# Define knn model with 3 neighbors and train it with the train data\n",
    "knn_3 = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_3.fit(X_train_23, y_train_23)\n",
    "\n",
    "# Predict crim\n",
    "pred_3 = knn_3.predict(X_test_23)\n",
    "\n",
    "# Compute and report MAPE\n",
    "compute_mape(y_test_23, pred_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.45104609024625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define knn model with 3 neighbors and train it with the train data (Hint: train and test data is the same as in the 2.2)\n",
    "knn_5 = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_5.fit(X_train_23, y_train_23)\n",
    "\n",
    "# Predict crim\n",
    "pred_5 = knn_5.predict(X_test_23)\n",
    "\n",
    "# Compute and report MAPE\n",
    "compute_mape(y_test_23, pred_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: The MAPE of the knn_3 model is 64.337. The MAPE of the knn_5 model is 98.45. Both of these models are better than our previous mean and median models because they both have smaller MAPEs. The best model is the knn_3 model because it has the smallest MAPE, meaning that on average the difference between our predictions and actual values is the smallest in the knn_3 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*End of Homework 2*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
